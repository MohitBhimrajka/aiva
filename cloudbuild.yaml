# =============================================================================
# ğŸš€ HR Pinnacle - Google Cloud Build Configuration
# =============================================================================
# This config builds and deploys both backend (FastAPI) and frontend (Next.js)
# to Google Cloud Run with full secret management and database migrations.
#
# Usage:
# - Manual: gcloud builds submit --config cloudbuild.yaml .
# - Auto: Set up Cloud Build trigger on main branch commits
# =============================================================================

steps:
  # =============================================================================
  # ğŸ”§ STEP 1: Verify Secrets Access
  # =============================================================================
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'verify-secrets'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "ğŸ” Verifying secrets access..."
        
        # Test secret access (just check if they exist)
        gcloud secrets versions access latest --secret="postgres-host" > /dev/null && echo "âœ… postgres-host accessible"
        gcloud secrets versions access latest --secret="postgres-user" > /dev/null && echo "âœ… postgres-user accessible"
        gcloud secrets versions access latest --secret="postgres-password" > /dev/null && echo "âœ… postgres-password accessible"
        gcloud secrets versions access latest --secret="postgres-db" > /dev/null && echo "âœ… postgres-db accessible"
        gcloud secrets versions access latest --secret="jwt-secret-key" > /dev/null && echo "âœ… jwt-secret-key accessible"
        gcloud secrets versions access latest --secret="gemini-api-key" > /dev/null && echo "âœ… gemini-api-key accessible"
        gcloud secrets versions access latest --secret="heygen-api-key" > /dev/null && echo "âœ… heygen-api-key accessible"
        gcloud secrets versions access latest --secret="heygen-webhook-secret" > /dev/null && echo "âœ… heygen-webhook-secret accessible"
        gcloud secrets versions access latest --secret="google-cloud-storage-bucket" > /dev/null && echo "âœ… google-cloud-storage-bucket accessible"
        
        echo "âœ… All secrets are accessible"

  # =============================================================================
  # ğŸ—ï¸ STEP 2: Build Backend Docker Image
  # =============================================================================
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-backend'
    args:
      - 'build'
      - '-f'
      - 'Dockerfile'
      - '-t'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REPO}/${_BACKEND_IMAGE_NAME}:$BUILD_ID'
      - '-t'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REPO}/${_BACKEND_IMAGE_NAME}:latest'
      - '.'
    waitFor: ['verify-secrets']

  # =============================================================================
  # ğŸ—ï¸ STEP 3: Build Frontend Docker Image
  # =============================================================================
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-frontend'
    dir: 'frontend'
    args:
      - 'build'
      - '-f'
      - 'Dockerfile'
      - '--build-arg'
      - 'NEXT_PUBLIC_API_URL=https://hr-backend-509502622137.us-central1.run.app'
      - '-t'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REPO}/${_FRONTEND_IMAGE_NAME}:$BUILD_ID'
      - '-t'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REPO}/${_FRONTEND_IMAGE_NAME}:latest'
      - '.'
    waitFor: ['verify-secrets']

  # =============================================================================
  # ğŸ“¦ STEP 4: Push Images to Artifact Registry
  # =============================================================================
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-backend'
    args: ['push', '--all-tags', '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REPO}/${_BACKEND_IMAGE_NAME}']
    waitFor: ['build-backend']

  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-frontend'
    args: ['push', '--all-tags', '${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REPO}/${_FRONTEND_IMAGE_NAME}']
    waitFor: ['build-frontend']

  # =============================================================================
  # ğŸš€ STEP 5: Deploy Backend to Cloud Run
  # =============================================================================
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'deploy-backend'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "ğŸš€ Deploying backend to Cloud Run..."
        
        gcloud run deploy ${_BACKEND_IMAGE_NAME} \
          --image ${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REPO}/${_BACKEND_IMAGE_NAME}:$BUILD_ID \
          --region ${_REGION} \
          --platform managed \
          --allow-unauthenticated \
          --memory 2Gi \
          --cpu 2 \
          --concurrency 80 \
          --timeout 900 \
          --max-instances 10 \
          --min-instances 0 \
          --port 8000 \
          --cpu-boost \
          --set-env-vars="POSTGRES_PORT=5432,JWT_ALGORITHM=HS256,JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30,LOG_LEVEL=INFO,MAX_STREAMING_DURATION_SECONDS=240,MAX_AUDIO_BYTES_PER_SESSION=52428800" \
          --set-secrets="POSTGRES_HOST=postgres-host:latest,POSTGRES_USER=postgres-user:latest,POSTGRES_DB=postgres-db:latest,POSTGRES_PASSWORD=postgres-password:latest,JWT_SECRET_KEY=jwt-secret-key:latest,GEMINI_API_KEY=gemini-api-key:latest,HEYGEN_API_KEY=heygen-api-key:latest,HEYGEN_API_KEY_1=heygen-api-key-1:latest,HEYGEN_API_KEY_2=heygen-api-key-2:latest,HEYGEN_API_KEY_3=heygen-api-key-3:latest,HEYGEN_API_KEY_4=heygen-api-key-4:latest,HEYGEN_API_KEY_5=heygen-api-key-5:latest,HEYGEN_API_KEY_6=heygen-api-key-6:latest,HEYGEN_API_KEY_7=heygen-api-key-7:latest,HEYGEN_API_KEY_8=heygen-api-key-8:latest,HEYGEN_WEBHOOK_SECRET=heygen-webhook-secret:latest,GOOGLE_CLOUD_STORAGE_BUCKET=google-cloud-storage-bucket:latest" \
          --execution-environment gen2 \
          
        echo "âœ… Backend deployed successfully"
    waitFor: ['push-backend']

  # =============================================================================
  # ğŸ—ƒï¸ STEP 6: Run Database Migrations and Seeding
  # =============================================================================
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'run-migrations'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "ğŸ—ƒï¸ Running database migrations and seeding..."
        
        # Get the backend service URL
        BACKEND_URL=$$(gcloud run services describe ${_BACKEND_IMAGE_NAME} --region=${_REGION} --format="value(status.url)")
        echo "Backend URL: $$BACKEND_URL"
        
        # Run migrations and seeding using the deployed container
        gcloud run jobs create hr-migrations-$BUILD_ID \
          --image ${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REPO}/${_BACKEND_IMAGE_NAME}:$BUILD_ID \
          --region ${_REGION} \
          --memory 1Gi \
          --cpu 1 \
          --task-timeout 600 \
          --max-retries 3 \
          --parallelism 1 \
          --set-env-vars="POSTGRES_PORT=5432,JWT_ALGORITHM=HS256,JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30,LOG_LEVEL=INFO" \
          --set-secrets="POSTGRES_HOST=postgres-host:latest,POSTGRES_USER=postgres-user:latest,POSTGRES_DB=postgres-db:latest,POSTGRES_PASSWORD=postgres-password:latest,JWT_SECRET_KEY=jwt-secret-key:latest" \
          --command="python" \
          --args="-c,\"import sys; sys.path.append('/app'); from scripts.seed_roles import seed_roles; from scripts.create_super_admin import create_super_admin; from scripts.seed_data import seed_database, seed_demo_user_data; from scripts.add_coding_questions import add_coding_questions; seed_roles(); create_super_admin(); seed_database(); seed_demo_user_data(); add_coding_questions(); print('âœ… Database migrations, seeding, and coding questions completed successfully!')\""
        
        # Execute the job
        gcloud run jobs execute hr-migrations-$BUILD_ID --region=${_REGION} --wait
        
        # Clean up the job
        gcloud run jobs delete hr-migrations-$BUILD_ID --region=${_REGION} --quiet
        
        echo "âœ… Database migrations and seeding completed"
    waitFor: ['deploy-backend']

  # =============================================================================
  # ğŸ¬ STEP 7: Sync Existing Videos from Storage to Database
  # =============================================================================
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'sync-videos'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "ğŸ¬ Syncing existing videos from storage to database..."
        
        # Run video sync using the deployed container
        gcloud run jobs create hr-video-sync-$BUILD_ID \
          --image ${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REPO}/${_BACKEND_IMAGE_NAME}:$BUILD_ID \
          --region ${_REGION} \
          --memory 1Gi \
          --cpu 1 \
          --task-timeout 600 \
          --max-retries 2 \
          --parallelism 1 \
          --set-env-vars="POSTGRES_PORT=5432,LOG_LEVEL=INFO,CLEANUP_ORPHANED=true" \
          --set-secrets="POSTGRES_HOST=postgres-host:latest,POSTGRES_USER=postgres-user:latest,POSTGRES_DB=postgres-db:latest,POSTGRES_PASSWORD=postgres-password:latest,GOOGLE_CLOUD_STORAGE_BUCKET=google-cloud-storage-bucket:latest" \
          --command="python" \
          --args="scripts/sync_videos_from_bucket.py"
        
        # Execute the video sync job
        echo "ğŸ”„ Starting video sync job..."
        gcloud run jobs execute hr-video-sync-$BUILD_ID --region=${_REGION} --wait
        
        # Clean up the job
        gcloud run jobs delete hr-video-sync-$BUILD_ID --region=${_REGION} --quiet
        
        echo "âœ… Video sync completed"
    waitFor: ['run-migrations']

  # =============================================================================
  # ğŸ¬ STEP 7: Start Continuous Video Generation (if needed)
  # =============================================================================
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'start-video-generation'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "ğŸ¬ Checking if continuous video generation is needed..."
        
        # Run video generation check using the deployed container
        gcloud run jobs create hr-video-generation-$BUILD_ID \
          --image ${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REPO}/${_BACKEND_IMAGE_NAME}:$BUILD_ID \
          --region ${_REGION} \
          --memory 1Gi \
          --cpu 1 \
          --task-timeout 120 \
          --max-retries 1 \
          --parallelism 1 \
          --set-env-vars="POSTGRES_PORT=5432,LOG_LEVEL=INFO" \
          --set-secrets="POSTGRES_HOST=postgres-host:latest,POSTGRES_USER=postgres-user:latest,POSTGRES_DB=postgres-db:latest,POSTGRES_PASSWORD=postgres-password:latest,HEYGEN_API_KEY=heygen-api-key:latest,HEYGEN_API_KEY_1=heygen-api-key-1:latest,HEYGEN_API_KEY_2=heygen-api-key-2:latest,HEYGEN_API_KEY_3=heygen-api-key-3:latest,HEYGEN_API_KEY_4=heygen-api-key-4:latest,HEYGEN_API_KEY_5=heygen-api-key-5:latest,HEYGEN_API_KEY_6=heygen-api-key-6:latest,HEYGEN_API_KEY_7=heygen-api-key-7:latest,HEYGEN_API_KEY_8=heygen-api-key-8:latest,GOOGLE_CLOUD_STORAGE_BUCKET=google-cloud-storage-bucket:latest" \
          --command="python" \
          --args="-c,\"import sys; sys.path.append('/app'); from scripts.continuous_video_generator import ContinuousVideoGenerator; import asyncio; generator = ContinuousVideoGenerator(check_interval_minutes=1, max_parallel=2); asyncio.run(generator.process_missing_videos()); print('âœ… Video generation check completed!')\""
        
        # Execute the job
        echo "ğŸ”„ Running video generation check..."
        gcloud run jobs execute hr-video-generation-$BUILD_ID --region=${_REGION} --wait || echo "Video generation check completed"
        
        # Clean up the job
        gcloud run jobs delete hr-video-generation-$BUILD_ID --region=${_REGION} --quiet
        
        echo "âœ… Video generation check completed"
    waitFor: ['sync-videos']

  # =============================================================================
  # ğŸŒ STEP 8: Deploy Frontend to Cloud Run
  # =============================================================================
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'deploy-frontend'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "ğŸŒ Deploying frontend to Cloud Run..."
        
        # Get the actual backend URL after deployment
        BACKEND_URL=$$(gcloud run services describe ${_BACKEND_IMAGE_NAME} --region=${_REGION} --format="value(status.url)")
        echo "Using backend URL: $$BACKEND_URL"
        
        gcloud run deploy ${_FRONTEND_IMAGE_NAME} \
          --image ${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_ARTIFACT_REPO}/${_FRONTEND_IMAGE_NAME}:$BUILD_ID \
          --region ${_REGION} \
          --platform managed \
          --allow-unauthenticated \
          --memory 512Mi \
          --cpu 1 \
          --concurrency 100 \
          --timeout 300 \
          --max-instances 10 \
          --min-instances 0 \
          --port 3000 \
          --set-env-vars="NEXT_PUBLIC_API_URL=$$BACKEND_URL" \
          --execution-environment gen2 \
          
        echo "âœ… Frontend deployed successfully"
    waitFor: ['push-frontend', 'start-video-generation']

  # =============================================================================
  # âœ¨ STEP 9: Post-Deployment Health Checks
  # =============================================================================
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'health-checks'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "ğŸ¥ Running post-deployment health checks..."
        
        # Get service URLs
        BACKEND_URL=$$(gcloud run services describe ${_BACKEND_IMAGE_NAME} --region=${_REGION} --format="value(status.url)")
        FRONTEND_URL=$$(gcloud run services describe ${_FRONTEND_IMAGE_NAME} --region=${_REGION} --format="value(status.url)")
        
        echo "ğŸ” Backend URL: $$BACKEND_URL"
        echo "ğŸ” Frontend URL: $$FRONTEND_URL"
        
        # Test backend health
        echo "Testing backend health endpoint..."
        curl -f "$$BACKEND_URL/api/health" || (echo "âŒ Backend health check failed" && exit 1)
        echo "âœ… Backend health check passed"
        
        # Test frontend
        echo "Testing frontend..."  
        curl -f "$$FRONTEND_URL" > /dev/null || (echo "âŒ Frontend health check failed" && exit 1)
        echo "âœ… Frontend health check passed"
        
        echo ""
        echo "ğŸ‰ ğŸ‰ ğŸ‰ DEPLOYMENT SUCCESSFUL! ğŸ‰ ğŸ‰ ğŸ‰"
        echo ""
        echo "ğŸ“± Frontend: $$FRONTEND_URL"
        echo "ğŸ”§ Backend:  $$BACKEND_URL"
        echo "ğŸ“š API Docs: $$BACKEND_URL/docs"
        echo ""
        echo "ğŸ” Your secrets are securely managed in Google Secret Manager"
        echo "ğŸ—ƒï¸ Database migrations and seeding have been applied"
        echo "ğŸ¬ Video-database relationships have been synchronized"
        echo "ğŸš€ Both services are running on Cloud Run"
    waitFor: ['deploy-frontend']

# =============================================================================
# ğŸ›ï¸ SUBSTITUTION VARIABLES
# =============================================================================
# These can be overridden at build time or set as defaults
substitutions:
  _REGION: "us-central1"
  _ARTIFACT_REPO: "hr-docker-repo"
  _BACKEND_IMAGE_NAME: "hr-backend"
  _FRONTEND_IMAGE_NAME: "hr-frontend"

# =============================================================================
# ğŸ“‹ BUILD OPTIONS
# =============================================================================
# Set build timeout (30 minutes)
timeout: '1800s'

options:
  # Use high-performance build machine
  machineType: 'E2_HIGHCPU_8'
  
  # Enable build logs streaming
  logging: CLOUD_LOGGING_ONLY

# =============================================================================
# ğŸ·ï¸ IMAGES TO BE STORED
# =============================================================================
# Images are pushed manually in the build steps above
# This avoids issues with SHORT_SHA validation before build execution

# =============================================================================
# ğŸ“š NEXT STEPS AFTER DEPLOYMENT:
# =============================================================================
# 1. Update your secrets in Google Secret Manager:
#    - postgres-host: Your actual PostgreSQL host
#    - postgres-user: Your database username  
#    - postgres-password: Your secure database password
#    - jwt-secret-key: A long, random secret key
#    - gemini-api-key: Your actual Gemini API key
#    - heygen-api-key: Your HeyGen API key for video generation
#    - google-cloud-storage-bucket: Your GCloud storage bucket name
#
# 2. Set up a Cloud Build trigger:
#    gcloud builds triggers create github \
#      --repo-name=hr-pinnacle \
#      --repo-owner=your-github-username \
#      --branch-pattern=main \
#      --build-config=cloudbuild.yaml
#
# 3. Configure your database (Cloud SQL PostgreSQL recommended):
#    - Create a Cloud SQL instance
#    - Update the postgres-host secret with the connection string
#    - Enable private IP if needed
#
# 4. Test video sync functionality locally (optional):
#    docker exec your-backend-container python scripts/test_video_sync_local.py
#
# 5. Set up custom domains (optional):
#    - Map your domain to the Cloud Run services
#    - Update CORS settings if needed
#
# ğŸ¬ VIDEO SYNC FEATURE:
# The deployment automatically syncs existing videos from your GCloud storage
# bucket to the database, ensuring video-question relationships are maintained
# across different database environments (dev/staging/production).
# =============================================================================
